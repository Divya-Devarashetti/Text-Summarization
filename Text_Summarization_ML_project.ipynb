{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPxsulH4cBDQByP3v3GzJM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Divya-Devarashetti/Text-Summarization-ML/blob/main/Text_Summarization_ML_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJG6RWH2eWp_",
        "outputId": "c8957207-7d43-4135-ff0b-60c47051d8b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [8][9]\n",
            "In the United Kingdom, early recorded usage of the \"sports car\" was in The Times newspaper in 1919. Examples of FR layout sports cars are the Caterham 7, Mazda MX-5, and the Dodge Viper. Examples of MR layout sports cars are the Ferrari 488, Ford GT and Toyota MR2. [39]\n",
            "Although front-wheel drive with the engine at the front (FF layout) is the most common layout for cars in general, it is not as common amongst traditional sports cars. Examples of FF layout sports cars are the Fiat Barchetta, Saab Sonett, or Opel Tigra. [54] The model was named after King Alfonso XIII of Spain, a patron of the car's chief designer and an enthusiast for the marque. E.g. Vintage cars at the time.\n"
          ]
        }
      ],
      "source": [
        "#importing some libraries\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import bs4 as BeautifulSoup\n",
        "import urllib.request  \n",
        "\n",
        "#fetching the content from the URL\n",
        "text_summ = urllib.request.urlopen('https://en.wikipedia.org/wiki/Sports_car')\n",
        "\n",
        "summ_read = text_summ.read()\n",
        "\n",
        "#parsing the URL content and storing in a variable\n",
        "summ_parsed = BeautifulSoup.BeautifulSoup(summ_read,'html.parser')\n",
        "\n",
        "#returning <p> tags\n",
        "paragraphs = summ_parsed.find_all('p')\n",
        "\n",
        "summ_content = ''\n",
        "\n",
        "#looping through the paragraphs and adding them to the variable\n",
        "for p in paragraphs:  \n",
        "    summ_content += p.text\n",
        "\n",
        "\n",
        "def _creating_dictionary_table(text_string) -> dict:\n",
        "   \n",
        "    #remove stop words\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    \n",
        "    words = word_tokenize(text_string)\n",
        "    \n",
        "    #reducing words to their root form\n",
        "    stem = PorterStemmer()\n",
        "    \n",
        "    #creating dictionary for the word frequency table\n",
        "    frequency_table = dict()\n",
        "    for w in words:\n",
        "        w = stem.stem(w)\n",
        "        if w in stop_words:\n",
        "            continue\n",
        "        if w in frequency_table:\n",
        "            frequency_table[w] += 1\n",
        "        else:\n",
        "            frequency_table[w] = 1\n",
        "\n",
        "    return frequency_table\n",
        "\n",
        "\n",
        "def _calculated_sentence_scores(sentences, frequency_table) -> dict:   \n",
        "\n",
        "    #algorithm for scoring a sentence by its words\n",
        "    sentence_weight = dict()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
        "        sentence_wordcount_without_stop_words = 0\n",
        "        for word_weight in frequency_table:\n",
        "            if word_weight in sentence.lower():\n",
        "                sentence_wordcount_without_stop_words += 1\n",
        "                if sentence[:7] in sentence_weight:\n",
        "                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\n",
        "                else:\n",
        "                    sentence_weight[sentence[:7]] = frequency_table[word_weight]\n",
        "\n",
        "        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words\n",
        "\n",
        "       \n",
        "\n",
        "    return sentence_weight\n",
        "\n",
        "def _calculated_average_score(sentence_weight) -> int:\n",
        "   \n",
        "    #calculating the average score for the sentences\n",
        "    sum_values = 0\n",
        "    for entry in sentence_weight:\n",
        "        sum_values += sentence_weight[entry]\n",
        "\n",
        "    #getting sentence average value from source text\n",
        "    average_score = (sum_values / len(sentence_weight))\n",
        "\n",
        "    return average_score\n",
        "\n",
        "def _get_article_summary(sentences, sentence_weight, threshold):\n",
        "    sentence_counter = 0\n",
        "    article_summary = ''\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] >= (threshold):\n",
        "            article_summary += \" \" + sentence\n",
        "            sentence_counter += 1\n",
        "\n",
        "    return article_summary\n",
        "\n",
        "def _run_article_summary(article):\n",
        "    \n",
        "    #creating a dictionary for the word frequency table\n",
        "    frequency_table = _creating_dictionary_table(article)\n",
        "\n",
        "    #tokenizing the sentences\n",
        "    sentences = sent_tokenize(article)\n",
        "\n",
        "    #algorithm for scoring a sentence by its words\n",
        "    sentence_scores = _calculated_sentence_scores(sentences, frequency_table)\n",
        "\n",
        "    #getting the threshold\n",
        "    threshold = _calculated_average_score(sentence_scores)\n",
        "\n",
        "    #producing the summary\n",
        "    article_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold)\n",
        "\n",
        "    return article_summary\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    summ_results = _run_article_summary(summ_content)\n",
        "    print(summ_results)"
      ]
    }
  ]
}